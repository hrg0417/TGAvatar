<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="3D Gaussian Blendshapes for Head Avatar Animation">
  <meta name="keywords" content="Parametric face models, facial animation, facial tracking, facial reenactment">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TGAvatar: Reconstructing 3D Gaussian Avatars with Transformer-based Tri-plane</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./assets/css/bulma.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./assets/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> 
  <script defer src="./assets/js/fontawesome.all.min.js"></script>
  <script src="./assets/js/bulma-carousel.min.js"></script>
  <script src="./assets/js/bulma-slider.min.js"></script>
  <script src="./assets/js/index.js"></script> 
  

</head>
<body>

      <!--
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>


      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>

    </div>

  </div>
</nav>
    -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">TGAvatar: Reconstructing 3D Gaussian Avatars with Transformer-based Tri-plane</h1>
          <div class="is-size-5 publication-authors"> 
            <span class="author-block">
              Ruigang Hu</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Xuekuan Wang</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Yichao Yan</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Cairong Zhao</a>
            </span>
          </div> 

          <div class="is-size-5 publication-authors">
            <span class="author-block">Visual and Intelligent Learning Lab, Tongji University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="assets/TGAvatar.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>              
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hrg0417/TGAvatar.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

     <img src="./assets/intro.png" class="center">
     
     <h2 class="subtitle has-text-centered" style="margin-top: 15px">
      TGAvatar reconstructs a 3D facial avatar from a monocular portrait video of a person. By leveraging 3D Gaussian Splatting \cite{kerbl20233d}, alongside 3DMM feature blending and a transformer based tri-plane module, TGAvatar gan generate lifelike novel views and expressions of the digital avatar.  
      </h2>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths"> 
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce TGAvatar, a novel framework for 3D head animation and reconstruction that revolutionizes the use of 3D Gaussian Splatting (3DGS). TGAvatar significantly advances rendering quality by leveraging the intricate properties of 3DGS to achieve detailed and realistic representations of human head geometries and textures. We use an innovative application of linear blending techniques to imitate 3D Morphable Model (3DMM) coefficients within 3DGS, thereby enabling precise and dynamic facial feature and expression modeling. Further enhancing TGAvatar's capabilities, a transformer based tri-plane module is incorporated to accurately infer spherical harmonics and alpha parameters. This integration is pivotal for the method, as it allows allows us to efficiently and precisely represent the visual characteristics of gaussians, tailored specifically to the intricate details of the head's components. Our exhaustive evaluations show that TGAvatar not only elevates the fidelity and realism of 3D head reconstructions but also sets a new standard by surpassing existing methods in rendering quality and computational efficiency.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Pipeline -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Pipeline</h2>
        <img src="./assets/process.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            TGAvatar process begins with the random initialization of a set of Gaussians with pose, rotation, and scale bases (\(P, Q, S\)) and bias terms (\(p_0, q_0, s_0\)). In addition, a transformer based tri-plane module is employed to ensure high-fidelity novel view synthesis. Specifically, we first use a transformer-based tri-plane decoder to predict tri-plane features. Subsequently, we incorporate a tri-plane module to extract hybrid features based on the pose of each Gaussian. Finally, these hybrid features are fed into an MLP network to infer opacity (\(\alpha\)) and spherical harmonics coefficients(SH) in each gaussian.
          </p>
        </div>

        <!-- <p> <FONT COLOR="#ff0000">TODO </FONT> </p> -->

        
        <div class="content has-text-centered">
          
          <video id="replay-video" controls="" preload="" playsinline="" loop="" width="100%">
            <source src="./assets/demo_final.mp4" type="video/mp4">
          </video>
        </div>
        

      </div>
    </div>
    <!--/ Pipeline -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparisons</h2>

        <div class="content has-text-justified">
          <p>
            Qualitative comparisons between our TGAvatar and INSTA, FlashAvatar and GaussianBlendshapes. Results are executed under the configurations specified in their works. For INSTA dataset, INSTA and GaussianBlendshapes provide pretrained models, therefore, these results are evaluated by their pretrained models. Our TGAvatar achieves better results, particularly in capturing details such as teeth, eyes, wrinkles and reflections.
          </p>
        </div>

        
        <div class="content has-text-centered">
          <video id="replay-video" controls="" muted="" preload="" playsinline="" loop="" width="100%">
            <source src="./assets/compare.mp4" type="video/mp4">
          </video>
        </div>
        
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-top: -30px">More Results</h2>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item id1">
          <video poster="" id="id1" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/id1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item id2">
          <video poster="" id="id2" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/id2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item id5">
          <video poster="" id="id5" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/id5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item id6">
          <video poster="" id="id6" autoplay controls muted loop playsinline height="100%">
            <source src="./assets/id6.mp4"  type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

</body>
</html>
